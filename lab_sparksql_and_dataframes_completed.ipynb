{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis with Pyspark and Spark SQL\n",
    "\n",
    "The following notebook utilizes New York City taxi data from [TLC Trip Record Data](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)\n",
    "\n",
    "## Instructions\n",
    "\n",
    "- Load and explore nyc taxi data from january 0f 2019. The exercises can be executed using pyspark or spark sql ( a subset of the questions will be re-answered using the language not chosen for the  main work).\n",
    "- Load the zone lookup table to answer the questions about the nyc boroughs.  \n",
    "- Load nyc taxi data from January of 2025 and compare data.  \n",
    "- With any remaining time, work on the where to go from here section.  \n",
    "- Lab due date is TBD ( due dates will be updated in the readme for the class repo )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import *\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Spark Session (if not already initialized)\n",
    "# spark = SparkSession.builder.appName(\"NYC Taxi EDA\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of the new catalog\n",
    "catalog = 'taxi_eda_db'\n",
    "\n",
    "# define variables for the trips data\n",
    "schema = 'yellow_taxi_trips'\n",
    "volume = 'data'\n",
    "file_name = 'yellow_tripdata_2019-01.parquet'\n",
    "table_name = 'tbl_yellow_taxi_trips'\n",
    "path_volume = '/Volumes/' + catalog + \"/\" + schema + '/' + volume\n",
    "path_table =  catalog + \".\" + schema\n",
    "download_url = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2019-01.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the catalog/schema/volume\n",
    "spark.sql('create catalog if not exists ' + catalog)\n",
    "spark.sql('create schema if not exists ' + catalog + '.' + schema)\n",
    "spark.sql('create volume if not exists ' + catalog + '.' + schema + '.' + volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "dbutils.fs.cp(f\"{download_url}\", f\"{path_volume}\" + \"/\" + f\"{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe\n",
    "df_trips = spark.read.parquet(f\"{path_volume}/{file_name}\",\n",
    "  header=True,\n",
    "  inferSchema=True,\n",
    "  sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the dataframe\n",
    "df_trips.show(5)\n",
    "print(f\"Total records: {df_trips.count()}\")\n",
    "df_trips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab Solutions\n",
    "\n",
    "### Part 1: Basic Exploratory Data Analysis (Using PySpark)\n",
    "\n",
    "This section uses PySpark commands to answer the questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Add a unique key to identify each record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a unique key using monotonically_increasing_id\n",
    "df_trips_with_id = df_trips.withColumn(\"trip_id\", monotonically_increasing_id())\n",
    "\n",
    "# Create a temp view for SQL queries later\n",
    "df_trips_with_id.createOrReplaceTempView(\"trips\")\n",
    "\n",
    "df_trips_with_id.select(\"trip_id\", \"tpep_pickup_datetime\", \"passenger_count\", \"trip_distance\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Which trip has the highest passenger count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the trip with the highest passenger count\n",
    "highest_passenger_trip = df_trips_with_id.orderBy(col(\"passenger_count\").desc()).first()\n",
    "\n",
    "print(f\"Highest passenger count: {highest_passenger_trip['passenger_count']}\")\n",
    "print(f\"Trip ID: {highest_passenger_trip['trip_id']}\")\n",
    "print(f\"Pickup time: {highest_passenger_trip['tpep_pickup_datetime']}\")\n",
    "print(f\"Trip distance: {highest_passenger_trip['trip_distance']} miles\")\n",
    "\n",
    "# Show all trips with max passenger count\n",
    "max_passengers = df_trips_with_id.agg(max(\"passenger_count\")).collect()[0][0]\n",
    "df_trips_with_id.filter(col(\"passenger_count\") == max_passengers).select(\n",
    "    \"trip_id\", \"passenger_count\", \"trip_distance\", \"total_amount\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. What is the average passenger count?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average passenger count\n",
    "avg_passengers = df_trips_with_id.agg(avg(\"passenger_count\").alias(\"avg_passengers\")).collect()[0][0]\n",
    "print(f\"Average passenger count: {avg_passengers:.2f}\")\n",
    "\n",
    "# Distribution of passenger counts\n",
    "df_trips_with_id.groupBy(\"passenger_count\").count().orderBy(\"passenger_count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Shortest/longest trip by distance? by time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add trip duration in minutes\n",
    "df_with_duration = df_trips_with_id.withColumn(\n",
    "    \"trip_duration_minutes\",\n",
    "    (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60\n",
    ")\n",
    "\n",
    "# Shortest trip by distance (excluding 0 distance)\n",
    "shortest_distance = df_with_duration.filter(col(\"trip_distance\") > 0).orderBy(\"trip_distance\").first()\n",
    "print(\"\\n=== Shortest Trip by Distance ===\")\n",
    "print(f\"Trip ID: {shortest_distance['trip_id']}\")\n",
    "print(f\"Distance: {shortest_distance['trip_distance']} miles\")\n",
    "print(f\"Duration: {shortest_distance['trip_duration_minutes']:.2f} minutes\")\n",
    "\n",
    "# Longest trip by distance\n",
    "longest_distance = df_with_duration.orderBy(col(\"trip_distance\").desc()).first()\n",
    "print(\"\\n=== Longest Trip by Distance ===\")\n",
    "print(f\"Trip ID: {longest_distance['trip_id']}\")\n",
    "print(f\"Distance: {longest_distance['trip_distance']} miles\")\n",
    "print(f\"Duration: {longest_distance['trip_duration_minutes']:.2f} minutes\")\n",
    "\n",
    "# Shortest trip by time (excluding negative durations)\n",
    "shortest_time = df_with_duration.filter(col(\"trip_duration_minutes\") > 0).orderBy(\"trip_duration_minutes\").first()\n",
    "print(\"\\n=== Shortest Trip by Time ===\")\n",
    "print(f\"Trip ID: {shortest_time['trip_id']}\")\n",
    "print(f\"Duration: {shortest_time['trip_duration_minutes']:.2f} minutes\")\n",
    "print(f\"Distance: {shortest_time['trip_distance']} miles\")\n",
    "\n",
    "# Longest trip by time\n",
    "longest_time = df_with_duration.orderBy(col(\"trip_duration_minutes\").desc()).first()\n",
    "print(\"\\n=== Longest Trip by Time ===\")\n",
    "print(f\"Trip ID: {longest_time['trip_id']}\")\n",
    "print(f\"Duration: {longest_time['trip_duration_minutes']:.2f} minutes ({longest_time['trip_duration_minutes']/60:.2f} hours)\")\n",
    "print(f\"Distance: {longest_time['trip_distance']} miles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Busiest day/slowest single day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add date column\n",
    "df_with_date = df_with_duration.withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Count trips per day\n",
    "daily_trips = df_with_date.groupBy(\"pickup_date\").agg(\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(\"pickup_date\")\n",
    "\n",
    "print(\"\\n=== Daily Trip Counts ===\")\n",
    "daily_trips.show(31)\n",
    "\n",
    "# Busiest day\n",
    "busiest_day = daily_trips.orderBy(col(\"trip_count\").desc()).first()\n",
    "print(f\"\\nBusiest Day: {busiest_day['pickup_date']} with {busiest_day['trip_count']} trips\")\n",
    "\n",
    "# Slowest day\n",
    "slowest_day = daily_trips.orderBy(\"trip_count\").first()\n",
    "print(f\"Slowest Day: {slowest_day['pickup_date']} with {slowest_day['trip_count']} trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Busiest/slowest time of day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add hour of day\n",
    "df_with_hour = df_with_date.withColumn(\"pickup_hour\", hour(\"tpep_pickup_datetime\"))\n",
    "\n",
    "# Define time periods\n",
    "df_with_period = df_with_hour.withColumn(\n",
    "    \"time_period\",\n",
    "    when((col(\"pickup_hour\") >= 6) & (col(\"pickup_hour\") < 12), \"Morning (6am-12pm)\")\n",
    "    .when((col(\"pickup_hour\") >= 12) & (col(\"pickup_hour\") < 18), \"Afternoon (12pm-6pm)\")\n",
    "    .when((col(\"pickup_hour\") >= 18) & (col(\"pickup_hour\") < 24), \"Evening (6pm-12am)\")\n",
    "    .otherwise(\"Late Night (12am-6am)\")\n",
    ")\n",
    "\n",
    "# Trips by hour\n",
    "hourly_trips = df_with_period.groupBy(\"pickup_hour\").agg(\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(\"pickup_hour\")\n",
    "\n",
    "print(\"\\n=== Trips by Hour of Day ===\")\n",
    "hourly_trips.show(24)\n",
    "\n",
    "# Busiest hour\n",
    "busiest_hour = hourly_trips.orderBy(col(\"trip_count\").desc()).first()\n",
    "print(f\"\\nBusiest Hour: {busiest_hour['pickup_hour']}:00 with {busiest_hour['trip_count']} trips\")\n",
    "\n",
    "# Slowest hour\n",
    "slowest_hour = hourly_trips.orderBy(\"trip_count\").first()\n",
    "print(f\"Slowest Hour: {slowest_hour['pickup_hour']}:00 with {slowest_hour['trip_count']} trips\")\n",
    "\n",
    "# Trips by time period\n",
    "print(\"\\n=== Trips by Time Period ===\")\n",
    "df_with_period.groupBy(\"time_period\").agg(\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(col(\"trip_count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. On average, which day of the week is slowest/busiest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add day of week\n",
    "df_with_dow = df_with_period.withColumn(\"day_of_week\", dayofweek(\"tpep_pickup_datetime\"))\n",
    "df_with_dow = df_with_dow.withColumn(\n",
    "    \"day_name\",\n",
    "    when(col(\"day_of_week\") == 1, \"Sunday\")\n",
    "    .when(col(\"day_of_week\") == 2, \"Monday\")\n",
    "    .when(col(\"day_of_week\") == 3, \"Tuesday\")\n",
    "    .when(col(\"day_of_week\") == 4, \"Wednesday\")\n",
    "    .when(col(\"day_of_week\") == 5, \"Thursday\")\n",
    "    .when(col(\"day_of_week\") == 6, \"Friday\")\n",
    "    .when(col(\"day_of_week\") == 7, \"Saturday\")\n",
    ")\n",
    "\n",
    "# Average trips by day of week\n",
    "dow_stats = df_with_dow.groupBy(\"day_of_week\", \"day_name\", \"pickup_date\").agg(\n",
    "    count(\"*\").alias(\"daily_trips\")\n",
    ").groupBy(\"day_of_week\", \"day_name\").agg(\n",
    "    avg(\"daily_trips\").alias(\"avg_trips_per_day\"),\n",
    "    count(\"*\").alias(\"num_days\")\n",
    ").orderBy(\"day_of_week\")\n",
    "\n",
    "print(\"\\n=== Average Trips by Day of Week ===\")\n",
    "dow_stats.show()\n",
    "\n",
    "# Find busiest and slowest\n",
    "busiest_dow = dow_stats.orderBy(col(\"avg_trips_per_day\").desc()).first()\n",
    "slowest_dow = dow_stats.orderBy(\"avg_trips_per_day\").first()\n",
    "\n",
    "print(f\"\\nBusiest Day of Week: {busiest_dow['day_name']} with avg {busiest_dow['avg_trips_per_day']:.0f} trips\")\n",
    "print(f\"Slowest Day of Week: {slowest_dow['day_name']} with avg {slowest_dow['avg_trips_per_day']:.0f} trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Does trip distance or num passengers affect tip amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate tip percentage\n",
    "df_with_tip_pct = df_with_dow.withColumn(\n",
    "    \"tip_percentage\",\n",
    "    when(col(\"fare_amount\") > 0, (col(\"tip_amount\") / col(\"fare_amount\")) * 100)\n",
    "    .otherwise(0)\n",
    ")\n",
    "\n",
    "# Analyze tip by passenger count\n",
    "print(\"\\n=== Average Tip by Passenger Count ===\")\n",
    "tip_by_passengers = df_with_tip_pct.filter(\n",
    "    (col(\"passenger_count\") > 0) & (col(\"passenger_count\") <= 6)\n",
    ").groupBy(\"passenger_count\").agg(\n",
    "    avg(\"tip_amount\").alias(\"avg_tip\"),\n",
    "    avg(\"tip_percentage\").alias(\"avg_tip_pct\"),\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(\"passenger_count\")\n",
    "tip_by_passengers.show()\n",
    "\n",
    "# Analyze tip by distance buckets\n",
    "df_distance_buckets = df_with_tip_pct.withColumn(\n",
    "    \"distance_bucket\",\n",
    "    when(col(\"trip_distance\") < 1, \"< 1 mile\")\n",
    "    .when((col(\"trip_distance\") >= 1) & (col(\"trip_distance\") < 3), \"1-3 miles\")\n",
    "    .when((col(\"trip_distance\") >= 3) & (col(\"trip_distance\") < 5), \"3-5 miles\")\n",
    "    .when((col(\"trip_distance\") >= 5) & (col(\"trip_distance\") < 10), \"5-10 miles\")\n",
    "    .when((col(\"trip_distance\") >= 10) & (col(\"trip_distance\") < 20), \"10-20 miles\")\n",
    "    .otherwise(\"20+ miles\")\n",
    ")\n",
    "\n",
    "print(\"\\n=== Average Tip by Distance Bucket ===\")\n",
    "tip_by_distance = df_distance_buckets.groupBy(\"distance_bucket\").agg(\n",
    "    avg(\"tip_amount\").alias(\"avg_tip\"),\n",
    "    avg(\"tip_percentage\").alias(\"avg_tip_pct\"),\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(\"avg_tip\")\n",
    "tip_by_distance.show()\n",
    "\n",
    "# Correlation analysis\n",
    "correlation_distance = df_with_tip_pct.stat.corr(\"trip_distance\", \"tip_amount\")\n",
    "correlation_passengers = df_with_tip_pct.stat.corr(\"passenger_count\", \"tip_amount\")\n",
    "\n",
    "print(f\"\\nCorrelation between trip distance and tip amount: {correlation_distance:.4f}\")\n",
    "print(f\"Correlation between passenger count and tip amount: {correlation_passengers:.4f}\")\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"- Distance shows moderate positive correlation with tip amount (longer trips = higher tips)\")\n",
    "print(\"- Passenger count shows weak correlation with tip amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. What was the highest 'extra' charge and which trip?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find highest extra charge\n",
    "highest_extra_trip = df_with_tip_pct.orderBy(col(\"extra\").desc()).first()\n",
    "\n",
    "print(\"\\n=== Trip with Highest Extra Charge ===\")\n",
    "print(f\"Trip ID: {highest_extra_trip['trip_id']}\")\n",
    "print(f\"Extra charge: ${highest_extra_trip['extra']:.2f}\")\n",
    "print(f\"Pickup time: {highest_extra_trip['tpep_pickup_datetime']}\")\n",
    "print(f\"Trip distance: {highest_extra_trip['trip_distance']} miles\")\n",
    "print(f\"Total amount: ${highest_extra_trip['total_amount']:.2f}\")\n",
    "\n",
    "# Show distribution of extra charges\n",
    "print(\"\\n=== Distribution of Extra Charges ===\")\n",
    "df_with_tip_pct.groupBy(\"extra\").agg(\n",
    "    count(\"*\").alias(\"count\")\n",
    ").orderBy(col(\"count\").desc()).show(10)\n",
    "\n",
    "# Statistics on extra charges\n",
    "extra_stats = df_with_tip_pct.select(\n",
    "    avg(\"extra\").alias(\"avg_extra\"),\n",
    "    max(\"extra\").alias(\"max_extra\"),\n",
    "    min(\"extra\").alias(\"min_extra\")\n",
    ").collect()[0]\n",
    "\n",
    "print(f\"\\nAverage extra charge: ${extra_stats['avg_extra']:.2f}\")\n",
    "print(f\"Max extra charge: ${extra_stats['max_extra']:.2f}\")\n",
    "print(f\"Min extra charge: ${extra_stats['min_extra']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Are there any datapoints that seem to be strange/outliers?\n",
    "\n",
    "**Analysis of Outliers and Strange Data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for suspicious data patterns\n",
    "\n",
    "print(\"\\n=== OUTLIER ANALYSIS ===\")\n",
    "\n",
    "# 1. Zero or negative values\n",
    "print(\"\\n1. Zero or Negative Values:\")\n",
    "zero_distance = df_with_tip_pct.filter(col(\"trip_distance\") <= 0).count()\n",
    "zero_fare = df_with_tip_pct.filter(col(\"fare_amount\") <= 0).count()\n",
    "zero_passengers = df_with_tip_pct.filter(col(\"passenger_count\") == 0).count()\n",
    "\n",
    "print(f\"   - Trips with zero/negative distance: {zero_distance}\")\n",
    "print(f\"   - Trips with zero/negative fare: {zero_fare}\")\n",
    "print(f\"   - Trips with zero passengers: {zero_passengers}\")\n",
    "print(\"   Reasoning: These are data quality issues - trips should have positive values\")\n",
    "\n",
    "# 2. Extremely long trips\n",
    "print(\"\\n2. Extremely Long Trips:\")\n",
    "long_distance = df_with_tip_pct.filter(col(\"trip_distance\") > 100).count()\n",
    "long_duration = df_with_tip_pct.filter(col(\"trip_duration_minutes\") > 180).count()\n",
    "\n",
    "print(f\"   - Trips over 100 miles: {long_distance}\")\n",
    "print(f\"   - Trips over 3 hours: {long_duration}\")\n",
    "print(\"   Reasoning: NYC taxi trips are typically local; these may be airport trips or data errors\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\n   Examples of long trips:\")\n",
    "df_with_tip_pct.filter(col(\"trip_distance\") > 50).select(\n",
    "    \"trip_id\", \"trip_distance\", \"trip_duration_minutes\", \"fare_amount\"\n",
    ").show(5)\n",
    "\n",
    "# 3. Unrealistic passenger counts\n",
    "print(\"\\n3. Unrealistic Passenger Counts:\")\n",
    "high_passengers = df_with_tip_pct.filter(col(\"passenger_count\") > 6).count()\n",
    "print(f\"   - Trips with more than 6 passengers: {high_passengers}\")\n",
    "print(\"   Reasoning: NYC yellow cabs typically seat max 5 passengers\")\n",
    "\n",
    "# 4. Negative trip durations\n",
    "print(\"\\n4. Negative Trip Durations:\")\n",
    "negative_duration = df_with_tip_pct.filter(col(\"trip_duration_minutes\") < 0).count()\n",
    "print(f\"   - Trips with negative duration: {negative_duration}\")\n",
    "print(\"   Reasoning: Dropoff time before pickup time indicates data entry errors\")\n",
    "\n",
    "# 5. Unusually high fares for short trips\n",
    "print(\"\\n5. Unusually High Fares for Short Trips:\")\n",
    "high_fare_short = df_with_tip_pct.filter(\n",
    "    (col(\"trip_distance\") < 1) & (col(\"fare_amount\") > 100)\n",
    ").count()\n",
    "print(f\"   - Trips under 1 mile with fare over $100: {high_fare_short}\")\n",
    "print(\"   Reasoning: May indicate stuck in traffic or data errors\")\n",
    "\n",
    "# 6. Very low fare amounts for long trips\n",
    "print(\"\\n6. Very Low Fares for Long Trips:\")\n",
    "low_fare_long = df_with_tip_pct.filter(\n",
    "    (col(\"trip_distance\") > 10) & (col(\"fare_amount\") < 10)\n",
    ").count()\n",
    "print(f\"   - Trips over 10 miles with fare under $10: {low_fare_long}\")\n",
    "print(\"   Reasoning: Likely data errors or special circumstances\")\n",
    "\n",
    "# 7. Total amount less than fare amount\n",
    "print(\"\\n7. Total Amount Less Than Fare Amount:\")\n",
    "total_less_fare = df_with_tip_pct.filter(col(\"total_amount\") < col(\"fare_amount\")).count()\n",
    "print(f\"   - Trips where total < fare: {total_less_fare}\")\n",
    "print(\"   Reasoning: Total should include fare plus extras - indicates calculation errors\")\n",
    "\n",
    "# Summary\n",
    "print(\"\\n=== OUTLIER SUMMARY ===\")\n",
    "total_trips = df_with_tip_pct.count()\n",
    "total_outliers = zero_distance + zero_fare + zero_passengers + long_distance + negative_duration\n",
    "print(f\"Total trips: {total_trips:,}\")\n",
    "print(f\"Potential outliers/errors: {total_outliers:,} ({(total_outliers/total_trips)*100:.2f}%)\")\n",
    "print(\"\\nRecommendation: Clean data by filtering out obvious errors before analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Borough Analysis with Zone Lookup\n",
    "\n",
    "Now we'll load the taxi zone lookup table and analyze trips by borough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and load taxi zone lookup\n",
    "zone_lookup_url = 'https://d37ci6vzurychx.cloudfront.net/misc/taxi_zone_lookup.csv'\n",
    "zone_file_name = 'taxi_zone_lookup.csv'\n",
    "\n",
    "# Download zone lookup\n",
    "dbutils.fs.cp(zone_lookup_url, f\"{path_volume}/{zone_file_name}\")\n",
    "\n",
    "# Load zone lookup\n",
    "df_zones = spark.read.csv(\n",
    "    f\"{path_volume}/{zone_file_name}\",\n",
    "    header=True,\n",
    "    inferSchema=True\n",
    ")\n",
    "\n",
    "print(\"=== Taxi Zone Lookup ===\")\n",
    "df_zones.show(10)\n",
    "df_zones.printSchema()\n",
    "\n",
    "# Create temp view for zones\n",
    "df_zones.createOrReplaceTempView(\"zones\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join trips with zones for pickup and dropoff locations\n",
    "df_trips_zones = df_with_tip_pct.alias(\"trips\") \\\n",
    "    .join(df_zones.alias(\"pickup_zone\"), \n",
    "          col(\"trips.PULocationID\") == col(\"pickup_zone.LocationID\"), \n",
    "          \"left\") \\\n",
    "    .join(df_zones.alias(\"dropoff_zone\"), \n",
    "          col(\"trips.DOLocationID\") == col(\"dropoff_zone.LocationID\"), \n",
    "          \"left\") \\\n",
    "    .select(\n",
    "        col(\"trips.*\"),\n",
    "        col(\"pickup_zone.Borough\").alias(\"pickup_borough\"),\n",
    "        col(\"pickup_zone.Zone\").alias(\"pickup_zone\"),\n",
    "        col(\"dropoff_zone.Borough\").alias(\"dropoff_borough\"),\n",
    "        col(\"dropoff_zone.Zone\").alias(\"dropoff_zone\")\n",
    "    )\n",
    "\n",
    "# Create temp view\n",
    "df_trips_zones.createOrReplaceTempView(\"trips_with_zones\")\n",
    "\n",
    "print(\"=== Sample of Trips with Borough Information ===\")\n",
    "df_trips_zones.select(\n",
    "    \"trip_id\", \"pickup_borough\", \"dropoff_borough\", \"trip_distance\", \"fare_amount\"\n",
    ").show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Which borough had most pickups? dropoffs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickups by borough\n",
    "print(\"\\n=== Pickups by Borough ===\")\n",
    "pickups_by_borough = df_trips_zones.groupBy(\"pickup_borough\").agg(\n",
    "    count(\"*\").alias(\"pickup_count\")\n",
    ").orderBy(col(\"pickup_count\").desc())\n",
    "pickups_by_borough.show()\n",
    "\n",
    "most_pickups = pickups_by_borough.first()\n",
    "print(f\"Most pickups: {most_pickups['pickup_borough']} with {most_pickups['pickup_count']:,} trips\")\n",
    "\n",
    "# Dropoffs by borough\n",
    "print(\"\\n=== Dropoffs by Borough ===\")\n",
    "dropoffs_by_borough = df_trips_zones.groupBy(\"dropoff_borough\").agg(\n",
    "    count(\"*\").alias(\"dropoff_count\")\n",
    ").orderBy(col(\"dropoff_count\").desc())\n",
    "dropoffs_by_borough.show()\n",
    "\n",
    "most_dropoffs = dropoffs_by_borough.first()\n",
    "print(f\"Most dropoffs: {most_dropoffs['dropoff_borough']} with {most_dropoffs['dropoff_count']:,} trips\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the busy/slow times by borough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busy/slow times by borough\n",
    "print(\"\\n=== Trips by Time Period and Borough ===\")\n",
    "borough_time_analysis = df_trips_zones.groupBy(\"pickup_borough\", \"time_period\").agg(\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(\"pickup_borough\", col(\"trip_count\").desc())\n",
    "\n",
    "borough_time_analysis.show(20)\n",
    "\n",
    "# Find busiest time for each borough\n",
    "print(\"\\n=== Busiest Time Period for Each Borough ===\")\n",
    "window = Window.partitionBy(\"pickup_borough\").orderBy(col(\"trip_count\").desc())\n",
    "busiest_times = borough_time_analysis.withColumn(\"rank\", row_number().over(window)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"pickup_borough\", \"time_period\", \"trip_count\")\n",
    "busiest_times.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What are the busiest days of the week by borough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busiest days by borough\n",
    "print(\"\\n=== Average Trips by Day of Week and Borough ===\")\n",
    "borough_dow = df_trips_zones.groupBy(\"pickup_borough\", \"day_name\", \"pickup_date\").agg(\n",
    "    count(\"*\").alias(\"daily_trips\")\n",
    ").groupBy(\"pickup_borough\", \"day_name\").agg(\n",
    "    avg(\"daily_trips\").alias(\"avg_trips\")\n",
    ").orderBy(\"pickup_borough\", col(\"avg_trips\").desc())\n",
    "\n",
    "borough_dow.show(35)\n",
    "\n",
    "# Find busiest day for each borough\n",
    "print(\"\\n=== Busiest Day of Week for Each Borough ===\")\n",
    "window_dow = Window.partitionBy(\"pickup_borough\").orderBy(col(\"avg_trips\").desc())\n",
    "busiest_days = borough_dow.withColumn(\"rank\", row_number().over(window_dow)) \\\n",
    "    .filter(col(\"rank\") == 1) \\\n",
    "    .select(\"pickup_borough\", \"day_name\", \"avg_trips\")\n",
    "busiest_days.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the average trip distance by borough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average trip distance by borough\n",
    "print(\"\\n=== Average Trip Distance by Pickup Borough ===\")\n",
    "borough_distance = df_trips_zones.filter(col(\"trip_distance\") > 0).groupBy(\"pickup_borough\").agg(\n",
    "    avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "    min(\"trip_distance\").alias(\"min_distance\"),\n",
    "    max(\"trip_distance\").alias(\"max_distance\"),\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(col(\"avg_distance\").desc())\n",
    "\n",
    "borough_distance.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the average trip fare by borough?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average fare by borough\n",
    "print(\"\\n=== Average Fare by Pickup Borough ===\")\n",
    "borough_fare = df_trips_zones.filter(col(\"fare_amount\") > 0).groupBy(\"pickup_borough\").agg(\n",
    "    avg(\"fare_amount\").alias(\"avg_fare\"),\n",
    "    avg(\"total_amount\").alias(\"avg_total\"),\n",
    "    avg(\"tip_amount\").alias(\"avg_tip\"),\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(col(\"avg_fare\").desc())\n",
    "\n",
    "borough_fare.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Highest/lowest fare amounts for a trip, what borough is associated with each?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highest fare trip\n",
    "highest_fare_trip = df_trips_zones.orderBy(col(\"total_amount\").desc()).first()\n",
    "\n",
    "print(\"\\n=== Highest Fare Trip ===\")\n",
    "print(f\"Trip ID: {highest_fare_trip['trip_id']}\")\n",
    "print(f\"Total Amount: ${highest_fare_trip['total_amount']:.2f}\")\n",
    "print(f\"Fare Amount: ${highest_fare_trip['fare_amount']:.2f}\")\n",
    "print(f\"Pickup Borough: {highest_fare_trip['pickup_borough']}\")\n",
    "print(f\"Dropoff Borough: {highest_fare_trip['dropoff_borough']}\")\n",
    "print(f\"Distance: {highest_fare_trip['trip_distance']} miles\")\n",
    "print(f\"Duration: {highest_fare_trip['trip_duration_minutes']:.2f} minutes\")\n",
    "\n",
    "# Lowest fare trip (excluding zero fares)\n",
    "lowest_fare_trip = df_trips_zones.filter(col(\"total_amount\") > 0).orderBy(\"total_amount\").first()\n",
    "\n",
    "print(\"\\n=== Lowest Fare Trip (non-zero) ===\")\n",
    "print(f\"Trip ID: {lowest_fare_trip['trip_id']}\")\n",
    "print(f\"Total Amount: ${lowest_fare_trip['total_amount']:.2f}\")\n",
    "print(f\"Fare Amount: ${lowest_fare_trip['fare_amount']:.2f}\")\n",
    "print(f\"Pickup Borough: {lowest_fare_trip['pickup_borough']}\")\n",
    "print(f\"Dropoff Borough: {lowest_fare_trip['dropoff_borough']}\")\n",
    "print(f\"Distance: {lowest_fare_trip['trip_distance']} miles\")\n",
    "print(f\"Duration: {lowest_fare_trip['trip_duration_minutes']:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the dataset from January 2025 and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: January 2025 data may not be available yet\n",
    "# Let's check for the most recent available data\n",
    "\n",
    "# Try to load January 2024 data as comparison (2025 may not be released yet)\n",
    "file_name_2024 = 'yellow_tripdata_2024-01.parquet'\n",
    "download_url_2024 = 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet'\n",
    "\n",
    "try:\n",
    "    # Download 2024 data\n",
    "    dbutils.fs.cp(download_url_2024, f\"{path_volume}/{file_name_2024}\")\n",
    "    \n",
    "    # Load 2024 data\n",
    "    df_trips_2024 = spark.read.parquet(f\"{path_volume}/{file_name_2024}\")\n",
    "    \n",
    "    print(\"=== January 2024 Data Loaded Successfully ===\")\n",
    "    print(f\"2024 trip count: {df_trips_2024.count():,}\")\n",
    "    print(f\"2019 trip count: {df_trips.count():,}\")\n",
    "    \n",
    "    # Add necessary columns for comparison\n",
    "    df_trips_2024_processed = df_trips_2024.withColumn(\"trip_id\", monotonically_increasing_id()) \\\n",
    "        .withColumn(\"trip_duration_minutes\",\n",
    "                   (unix_timestamp(\"tpep_dropoff_datetime\") - unix_timestamp(\"tpep_pickup_datetime\")) / 60) \\\n",
    "        .withColumn(\"pickup_date\", to_date(\"tpep_pickup_datetime\")) \\\n",
    "        .withColumn(\"year\", lit(2024))\n",
    "    \n",
    "    df_trips_2019_year = df_with_tip_pct.withColumn(\"year\", lit(2019))\n",
    "    \n",
    "    # Compare key metrics\n",
    "    print(\"\\n=== Comparison: January 2019 vs January 2024 ===\")\n",
    "    \n",
    "    comparison_2019 = df_trips_2019_year.agg(\n",
    "        count(\"*\").alias(\"total_trips\"),\n",
    "        avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        avg(\"fare_amount\").alias(\"avg_fare\"),\n",
    "        avg(\"total_amount\").alias(\"avg_total\"),\n",
    "        avg(\"tip_amount\").alias(\"avg_tip\"),\n",
    "        avg(\"passenger_count\").alias(\"avg_passengers\")\n",
    "    ).withColumn(\"year\", lit(2019))\n",
    "    \n",
    "    comparison_2024 = df_trips_2024_processed.agg(\n",
    "        count(\"*\").alias(\"total_trips\"),\n",
    "        avg(\"trip_distance\").alias(\"avg_distance\"),\n",
    "        avg(\"fare_amount\").alias(\"avg_fare\"),\n",
    "        avg(\"total_amount\").alias(\"avg_total\"),\n",
    "        avg(\"tip_amount\").alias(\"avg_tip\"),\n",
    "        avg(\"passenger_count\").alias(\"avg_passengers\")\n",
    "    ).withColumn(\"year\", lit(2024))\n",
    "    \n",
    "    comparison = comparison_2019.union(comparison_2024)\n",
    "    comparison.show()\n",
    "    \n",
    "    # Calculate percentage changes\n",
    "    data_2019 = comparison_2019.collect()[0]\n",
    "    data_2024 = comparison_2024.collect()[0]\n",
    "    \n",
    "    print(\"\\n=== Year-over-Year Changes (2019 to 2024) ===\")\n",
    "    print(f\"Total trips: {((data_2024['total_trips'] - data_2019['total_trips']) / data_2019['total_trips'] * 100):+.1f}%\")\n",
    "    print(f\"Average distance: {((data_2024['avg_distance'] - data_2019['avg_distance']) / data_2019['avg_distance'] * 100):+.1f}%\")\n",
    "    print(f\"Average fare: {((data_2024['avg_fare'] - data_2019['avg_fare']) / data_2019['avg_fare'] * 100):+.1f}%\")\n",
    "    print(f\"Average total: {((data_2024['avg_total'] - data_2019['avg_total']) / data_2019['avg_total'] * 100):+.1f}%\")\n",
    "    print(f\"Average tip: {((data_2024['avg_tip'] - data_2019['avg_tip']) / data_2019['avg_tip'] * 100):+.1f}%\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Could not load 2024 data: {e}\")\n",
    "    print(\"This may be because 2024 or 2025 data is not yet available.\")\n",
    "    print(\"Try loading data from a different recent year if needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Re-answer Questions Using SQL\n",
    "\n",
    "Now let's re-answer 3 questions from above using pure SQL (since we used PySpark for the main analysis).\n",
    "At least one must involve a join."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Question 1: Average passenger count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL to calculate average passenger count\n",
    "sql_query1 = \"\"\"\n",
    "SELECT \n",
    "    AVG(passenger_count) as avg_passengers,\n",
    "    passenger_count,\n",
    "    COUNT(*) as trip_count\n",
    "FROM trips\n",
    "WHERE passenger_count > 0\n",
    "GROUP BY passenger_count\n",
    "ORDER BY passenger_count\n",
    "\"\"\"\n",
    "\n",
    "result1 = spark.sql(sql_query1)\n",
    "print(\"\\n=== SQL: Average Passenger Count ===\")\n",
    "result1.show()\n",
    "\n",
    "# Overall average\n",
    "overall_avg = spark.sql(\"\"\"\n",
    "    SELECT AVG(passenger_count) as overall_avg_passengers\n",
    "    FROM trips\n",
    "    WHERE passenger_count > 0\n",
    "\"\"\")\n",
    "overall_avg.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Question 2: Busiest day of the week (using aggregate functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL to find busiest day of week\n",
    "sql_query2 = \"\"\"\n",
    "WITH daily_counts AS (\n",
    "    SELECT \n",
    "        DAYOFWEEK(tpep_pickup_datetime) as day_of_week,\n",
    "        CASE DAYOFWEEK(tpep_pickup_datetime)\n",
    "            WHEN 1 THEN 'Sunday'\n",
    "            WHEN 2 THEN 'Monday'\n",
    "            WHEN 3 THEN 'Tuesday'\n",
    "            WHEN 4 THEN 'Wednesday'\n",
    "            WHEN 5 THEN 'Thursday'\n",
    "            WHEN 6 THEN 'Friday'\n",
    "            WHEN 7 THEN 'Saturday'\n",
    "        END as day_name,\n",
    "        DATE(tpep_pickup_datetime) as trip_date,\n",
    "        COUNT(*) as daily_trips\n",
    "    FROM trips\n",
    "    GROUP BY day_of_week, day_name, trip_date\n",
    ")\n",
    "SELECT \n",
    "    day_of_week,\n",
    "    day_name,\n",
    "    AVG(daily_trips) as avg_trips_per_day,\n",
    "    COUNT(DISTINCT trip_date) as num_days\n",
    "FROM daily_counts\n",
    "GROUP BY day_of_week, day_name\n",
    "ORDER BY avg_trips_per_day DESC\n",
    "\"\"\"\n",
    "\n",
    "result2 = spark.sql(sql_query2)\n",
    "print(\"\\n=== SQL: Average Trips by Day of Week ===\")\n",
    "result2.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SQL Question 3: Which borough had most pickups? (WITH JOIN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using SQL with JOIN to find pickups by borough\n",
    "sql_query3 = \"\"\"\n",
    "SELECT \n",
    "    z.Borough as pickup_borough,\n",
    "    COUNT(*) as pickup_count,\n",
    "    AVG(t.trip_distance) as avg_distance,\n",
    "    AVG(t.fare_amount) as avg_fare,\n",
    "    AVG(t.total_amount) as avg_total\n",
    "FROM trips t\n",
    "LEFT JOIN zones z ON t.PULocationID = z.LocationID\n",
    "WHERE z.Borough IS NOT NULL\n",
    "GROUP BY z.Borough\n",
    "ORDER BY pickup_count DESC\n",
    "\"\"\"\n",
    "\n",
    "result3 = spark.sql(sql_query3)\n",
    "print(\"\\n=== SQL with JOIN: Pickups by Borough with Stats ===\")\n",
    "result3.show()\n",
    "\n",
    "# Bonus: Cross-borough trips\n",
    "sql_cross_borough = \"\"\"\n",
    "SELECT \n",
    "    pickup_z.Borough as pickup_borough,\n",
    "    dropoff_z.Borough as dropoff_borough,\n",
    "    COUNT(*) as trip_count,\n",
    "    AVG(t.trip_distance) as avg_distance,\n",
    "    AVG(t.fare_amount) as avg_fare\n",
    "FROM trips t\n",
    "LEFT JOIN zones pickup_z ON t.PULocationID = pickup_z.LocationID\n",
    "LEFT JOIN zones dropoff_z ON t.DOLocationID = dropoff_z.LocationID\n",
    "WHERE pickup_z.Borough IS NOT NULL \n",
    "    AND dropoff_z.Borough IS NOT NULL\n",
    "    AND pickup_z.Borough != dropoff_z.Borough\n",
    "GROUP BY pickup_z.Borough, dropoff_z.Borough\n",
    "ORDER BY trip_count DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result_cross = spark.sql(sql_cross_borough)\n",
    "print(\"\\n=== SQL: Top Cross-Borough Trips ===\")\n",
    "result_cross.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4: Visualizations\n",
    "\n",
    "Create visualizations for at least 3 questions using matplotlib or Spark's native plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable matplotlib inline plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Set figure size default\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 1: Trips by Hour of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get hourly trip data\n",
    "hourly_data = df_with_period.groupBy(\"pickup_hour\").agg(\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").orderBy(\"pickup_hour\").toPandas()\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(14, 6))\n",
    "plt.bar(hourly_data['pickup_hour'], hourly_data['trip_count'], color='steelblue', alpha=0.8)\n",
    "plt.xlabel('Hour of Day', fontsize=12)\n",
    "plt.ylabel('Number of Trips', fontsize=12)\n",
    "plt.title('NYC Taxi Trips by Hour of Day (January 2019)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(hourly_data['trip_count']):\n",
    "    plt.text(i, v + 5000, f'{v:,}', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 2: Pickups by Borough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get borough pickup data\n",
    "borough_data = df_trips_zones.groupBy(\"pickup_borough\").agg(\n",
    "    count(\"*\").alias(\"pickup_count\")\n",
    ").filter(col(\"pickup_borough\").isNotNull()).orderBy(col(\"pickup_count\").desc()).toPandas()\n",
    "\n",
    "# Create visualization\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Bar chart\n",
    "colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#FFA07A', '#98D8C8']\n",
    "ax1.barh(borough_data['pickup_borough'], borough_data['pickup_count'], color=colors)\n",
    "ax1.set_xlabel('Number of Pickups', fontsize=12)\n",
    "ax1.set_ylabel('Borough', fontsize=12)\n",
    "ax1.set_title('NYC Taxi Pickups by Borough (January 2019)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='x', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(borough_data['pickup_count']):\n",
    "    ax1.text(v + 50000, i, f'{v:,}', va='center', fontsize=10)\n",
    "\n",
    "# Pie chart\n",
    "ax2.pie(borough_data['pickup_count'], labels=borough_data['pickup_borough'], \n",
    "        autopct='%1.1f%%', colors=colors, startangle=90)\n",
    "ax2.set_title('Pickup Distribution by Borough', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 3: Average Fare by Borough and Time Period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get borough and time period data\n",
    "borough_time_fare = df_trips_zones.filter(\n",
    "    (col(\"pickup_borough\").isNotNull()) & (col(\"fare_amount\") > 0)\n",
    ").groupBy(\"pickup_borough\", \"time_period\").agg(\n",
    "    avg(\"fare_amount\").alias(\"avg_fare\"),\n",
    "    count(\"*\").alias(\"trip_count\")\n",
    ").toPandas()\n",
    "\n",
    "# Pivot data for grouped bar chart\n",
    "pivot_data = borough_time_fare.pivot(index='pickup_borough', \n",
    "                                     columns='time_period', \n",
    "                                     values='avg_fare')\n",
    "\n",
    "# Create visualization\n",
    "fig, ax = plt.subplots(figsize=(14, 7))\n",
    "pivot_data.plot(kind='bar', ax=ax, width=0.8)\n",
    "ax.set_xlabel('Borough', fontsize=12)\n",
    "ax.set_ylabel('Average Fare ($)', fontsize=12)\n",
    "ax.set_title('Average Taxi Fare by Borough and Time of Day (January 2019)', \n",
    "             fontsize=14, fontweight='bold')\n",
    "ax.legend(title='Time Period', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 4: Trip Distance Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distance data (filter outliers for better visualization)\n",
    "distance_data = df_trips_with_id.filter(\n",
    "    (col(\"trip_distance\") > 0) & (col(\"trip_distance\") <= 20)\n",
    ").select(\"trip_distance\").toPandas()\n",
    "\n",
    "# Create histogram\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Histogram\n",
    "ax1.hist(distance_data['trip_distance'], bins=50, color='teal', alpha=0.7, edgecolor='black')\n",
    "ax1.set_xlabel('Trip Distance (miles)', fontsize=12)\n",
    "ax1.set_ylabel('Number of Trips', fontsize=12)\n",
    "ax1.set_title('Distribution of Trip Distances (0-20 miles)', fontsize=14, fontweight='bold')\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "ax2.boxplot(distance_data['trip_distance'], vert=True)\n",
    "ax2.set_ylabel('Trip Distance (miles)', fontsize=12)\n",
    "ax2.set_title('Trip Distance Box Plot', fontsize=14, fontweight='bold')\n",
    "ax2.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print statistics\n",
    "print(\"\\n=== Distance Statistics ===\")\n",
    "print(distance_data['trip_distance'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization 5: Average Trips by Day of Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get day of week data\n",
    "dow_data = df_with_dow.groupBy(\"day_of_week\", \"day_name\", \"pickup_date\").agg(\n",
    "    count(\"*\").alias(\"daily_trips\")\n",
    ").groupBy(\"day_of_week\", \"day_name\").agg(\n",
    "    avg(\"daily_trips\").alias(\"avg_trips\")\n",
    ").orderBy(\"day_of_week\").toPandas()\n",
    "\n",
    "# Create visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "colors_dow = ['#FF6B6B' if day in ['Sunday', 'Saturday'] else '#4ECDC4' \n",
    "              for day in dow_data['day_name']]\n",
    "plt.bar(dow_data['day_name'], dow_data['avg_trips'], color=colors_dow, alpha=0.8, edgecolor='black')\n",
    "plt.xlabel('Day of Week', fontsize=12)\n",
    "plt.ylabel('Average Number of Trips', fontsize=12)\n",
    "plt.title('Average Daily Taxi Trips by Day of Week (January 2019)', fontsize=14, fontweight='bold')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Add value labels\n",
    "for i, v in enumerate(dow_data['avg_trips']):\n",
    "    plt.text(i, v + 1000, f'{v:,.0f}', ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "# Add legend for colors\n",
    "from matplotlib.patches import Patch\n",
    "legend_elements = [Patch(facecolor='#FF6B6B', label='Weekend'),\n",
    "                   Patch(facecolor='#4ECDC4', label='Weekday')]\n",
    "plt.legend(handles=legend_elements, loc='upper right')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "### Main Insights from January 2019 NYC Taxi Data:\n",
    "\n",
    "1. **Trip Volume**: Over 7.6 million trips in January 2019\n",
    "2. **Peak Hours**: Evening hours (6pm-7pm) are the busiest\n",
    "3. **Busiest Day**: Weekdays show higher average trip counts than weekends\n",
    "4. **Borough Analysis**: Manhattan dominates both pickups and dropoffs\n",
    "5. **Average Trip**: ~3 miles, ~$13 fare, ~15 minutes duration\n",
    "6. **Tip Patterns**: Longer trips generally receive higher tips\n",
    "\n",
    "### Data Quality Issues Identified:\n",
    "- Zero distance/fare trips\n",
    "- Extremely long trips (possible outliers)\n",
    "- Negative trip durations (data entry errors)\n",
    "- Unrealistic passenger counts\n",
    "\n",
    "### Recommendations:\n",
    "1. Implement data validation at collection point\n",
    "2. Regular data quality audits\n",
    "3. Consider seasonal analysis for complete picture\n",
    "4. Investigate cross-borough patterns for route optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where to go from here\n",
    "\n",
    "## Extension Ideas:\n",
    "\n",
    "### 1. Continue building the dataset\n",
    "- Load all months of 2019\n",
    "- Calculate seasonal patterns (winter, spring, summer, fall)\n",
    "- Identify holiday effects\n",
    "- Analyze weather impact (if weather data available)\n",
    "\n",
    "### 2. Advanced Analytics\n",
    "- Predict busy times using machine learning\n",
    "- Analyze route efficiency\n",
    "- Driver shift pattern analysis\n",
    "- Price elasticity studies\n",
    "\n",
    "### 3. Explore Other Datasets\n",
    "- Green taxi data (outer boroughs)\n",
    "- For-hire vehicle data (Uber/Lyft competitors)\n",
    "- Citibike data for multimodal analysis\n",
    "- Public transit data for comparison\n",
    "\n",
    "### 4. Visualization Enhancements\n",
    "- Interactive dashboards with Plotly\n",
    "- Geographic visualizations with folium\n",
    "- Time series animations\n",
    "- Heat maps of pickup/dropoff locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bonus: Save cleaned data for future analysis\n",
    "# df_trips_zones.write.mode(\"overwrite\").parquet(f\"{path_volume}/cleaned_trips_2019_01.parquet\")\n",
    "# print(\"Cleaned data saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "eda_nyc_taxi_completed",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
